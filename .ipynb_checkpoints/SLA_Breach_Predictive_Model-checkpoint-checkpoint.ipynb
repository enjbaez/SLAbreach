{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa3153a",
   "metadata": {},
   "source": [
    "# Predictive SLA‑Breach Model\n",
    "This notebook demonstrates an **end‑to‑end workflow** to explore, feature‑engineer and train a model that predicts whether a pharmacy benefit change‑request will breach the 5‑day service‑level agreement (SLA).\n",
    "\n",
    "**Dataset:** synthetic 500‑row sample generated for prototyping (`dummy_change_request_data.csv`).\n",
    "\n",
    "**Pipeline outline:**\n",
    "1. Load & validate data\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Feature Engineering\n",
    "4. Train/Test split\n",
    "5. Model training (Logistic Regression + Gradient Boosting)\n",
    "6. Evaluation & interpretation\n",
    "7. Save model artifact\n",
    "\n",
    "*Feel free to run each cell sequentially or adapt the code for your production environment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2406d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For modeling\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, RocCurveDisplay\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import joblib  # for saving model\n",
    "\n",
    "# Load data\n",
    "csv_path = \"/mnt/data/dummy_change_request_data.csv\"\n",
    "df = pd.read_csv(csv_path, dtype=str)\n",
    "\n",
    "# Parse dates\n",
    "date_cols = [\n",
    "    \"cr date created\", \"cr date closed\",\n",
    "    \"test results received date\", \"test results approved date\"\n",
    "]\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], format=\"%Y%m%d\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da03980b",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76632756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# SLA durations\n",
    "df['request_SLA_days'] = (df['cr date closed'] - df['cr date created']).dt.days\n",
    "df['testing_SLA_days'] = (df['test results approved date'] - df['test results received date']).dt.days\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "df['request_SLA_days'].hist(ax=ax)\n",
    "ax.set_title(\"Distribution of Request SLA (days)\")\n",
    "ax.set_xlabel(\"Days\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b8630",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Binary target: breach if request_SLA_days > 5\n",
    "SLA_THRESHOLD = 5\n",
    "df['breach'] = (df['request_SLA_days'] > SLA_THRESHOLD).astype(int)\n",
    "\n",
    "# Base features\n",
    "df['month'] = df['cr date created'].dt.month\n",
    "df['year'] = df['cr date created'].dt.year\n",
    "\n",
    "feature_cols = [\n",
    "    'request_SLA_days', 'testing_SLA_days', 'month', 'year', 'category'\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['breach']\n",
    "\n",
    "# Categorical cols\n",
    "cat_features = ['category']\n",
    "num_features = ['request_SLA_days', 'testing_SLA_days', 'month', 'year']\n",
    "\n",
    "# Preprocess: one‑hot encode category\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features),\n",
    "        ('num', 'passthrough', num_features)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5322b3",
   "metadata": {},
   "source": [
    "## 3. Train/Test Split & Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39033df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Logistic Regression pipeline\n",
    "logreg_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Gradient Boosting pipeline\n",
    "gb_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': logreg_pipeline,\n",
    "    'GradientBoosting': gb_pipeline\n",
    "}\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"AUC:\", round(auc, 3))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957323f2",
   "metadata": {},
   "source": [
    "## 4. Evaluation: ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a67abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = gb_pipeline  # choose based on AUC above\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e44c9",
   "metadata": {},
   "source": [
    "## 5. Save Model Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63501e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"/mnt/data/gb_sla_breach_model.pkl\"\n",
    "joblib.dump(best_model, model_path)\n",
    "print(\"Model saved to:\", model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59867890",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Next Steps\n",
    "* Integrate with live SharePoint data via Power Automate.\n",
    "* Schedule daily inference job and write predictions back to a risk‑monitoring list.\n",
    "* Enhance feature set with rolling backlog metrics and requester metadata.\n",
    "* Perform hyper‑parameter tuning (e.g., `GridSearchCV`) for production deployment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
